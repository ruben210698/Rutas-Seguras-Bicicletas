\section{Obtención de Identificadores de Vias}

Los identificadores de las vías serán los que permitan la cohesión entre los distintos conjuntos de datos que aquí se están tratando. Todos ellos tienen en común propiedades relativas a calles, aunque no es posible enlazarlos por el nombre de un modo simple.
La obtención de las palabras clave de estos títulos permitiría un enlazado bastante eficaz entre ellos, aunque con un coste computacional muy elevado y sería muy ineficaz para una aplicación móvil como es el caso de este proyecto.

El identificador de las vías es necesario para el enlazado de las mismas (es parte de la URI de estos recursos) y sería conveniente que datasets posteriores tuviesen dicha información, ya que seguirían las pautas de los vocabularios definidos para ellos.

Al estar utilizando conjuntos de datos que aun no han tenido en cuenta estos requerimientos y al ser necesario para la creación del recurso de las vías, se ha creado una función que lo obtenga a partir del dataset de callejero \cite{datosmadrid_callejero}, el cual si contiene tanto nombres como identificadores y ha sufrido las mismas transformaciones, es decir, para una misma calle debería tener las mismas palabras clave. Para una mayor eficacia en la búsqueda se comprueba el tipo de vía que es y su nombre en varias vueltas, aumentando el margen de error en cada una de ellas.
Se ha utilizado el código mostrado en \ref{cod:crearFichNombresId} y posteriormente se detallará su funcionamiento.

\lstinputlisting[style=Python1, label = {cod:crearFichNombresId}, caption=Función crearFichNombresId]{codigo/crearFichNombresId.py}

En este código se hace un recorrido por dos datasets, primero en el que se quieren añadir los identificadores (Accidentes, CallesTranquilas o Ciclocarriles), el cual tiene únicamente los nombres de sus calles. El segundo recorrido se hace a través del Callejero de Madrid antes mencionado. Éste último contiene tanto los nombres como los identificadores y en el caso de que alguno de sus nombres coincida, el id de ese registro será copiado en el otro conjunto. Para ello, por cada registro del dataset al que queremos añadir este valor, se hará un recorrido completo al callejero hasta encontrar ese nombre.

Debido a la cantidad de errores que pueden ocurrir en este proceso se realiza la búsqueda varias veces. Primeramente, se dan 4 vueltas comprobando que el tipo de vía coincida en ambos datasets. En cada iteración se aumenta el margen de error permitido (como se observa en el código \ref{cod:checkearPalabras}). En las 4 siguientes iteraciones se sigue el mismo proceso, aunque sin comprobar el tipo de vía en el caso de que sea omitible. Hay ciertos tipos que no pueden ser obviados de esta comprobación: ``AUTOVIA``, ``POBLADO``, ``VALLE``, ``ESCALINATA``, ``PASO ELEVADO``, ``SENDA CICLABLE``, ``GALERIA``, ``CAÑADA``, ``AUTOPISTA``, ``POLIGONO``, ``RONDA``, ``AEROPUERTO``, ``PUENTE``, ``TRAVESIA``, ``PLAZUELA``, ``CALLEJON``, ``COSTANILLA``, ``JARDIN``, ``ARROYO``, ``PARTICULAR``, ``TRASERA``, ``COLONIA``. Estos casos se han considerado como posibles fuentes de nombres y se ha decidido que sea obligatorio que coincida la tipología en ambos conjuntos (por ejemplo, no puede ser igual la Calle del Atazar que el Poblado del Atazar).

Todas estas iteraciones se realizan haciendo una búsqueda por todo el callejero de Madrid en cada una de ellas. Es decir, se van comprobando todas las vías de menor a mayor margen de error, de forma que se cruce con la que tenga más similitud, o por lo menos, no menos coincidencia que otra.


\lstinputlisting[style=Python1, label = {cod:checkearPalabras}, caption=Función checkearPalabras]{codigo/checkearPalabras.py}

En la función \ref{cod:checkearPalabras} se detalla el funcionamiento de la comprobación de nombres al que antes se hacia referencia.
Primero se transforma a mayúsculas y se eliminan caracteres especiales y espacios para una comparación más eficaz.

Se puede observar que está dividido en 4 secciones que corresponderían a las rondas de error que se aplicaban anteriormente.
En la primera se comprueba que sea exactamente igual. La gran mayoría de elementos son cruzados en esta primera iteración ya que ha sido refinado anteriormente y reducido a palabras clave. Hay una alta probabilidad de que los elementos de un dataset y otro sean iguales.

En caso contrario, para la segunda vuelta aplicada se le permitirá un carácter añadido o eliminado. Este es el caso por ejemplo de palabras acabas en ``s`` u otras erratas. Para la tercera vuelta se le permitirá la sustitución de un carácter por otro, es decir, añadir y eliminar un carácter. Esto permite errores como cambios de vocales o erratas de sustitución de letras. Para la cuarta y última vuelta se tiene en cuenta la longitud de la cadena. Para nombres compuestos y extensos es más probable que ocurran erratas, por lo tanto, a mayor nombre mayor margen de error permitido.

Como se puede observar en el código \ref{cod:checkearPalabras}, tras los pasos 2, 3 y 4 se imprime por terminal la transformación realizada. Esto permite al desarrollador comprobar el buen funcionamiento del programa y, en caso de revisarlo y encontrar elementos mal emparejados, poder modificarlos manualmente antes de que se añadan a la aplicación final. Para el paso 1 no es necesario, ya que el nombre es exacto, pero las siguientes al permitir margen de error, pueden ocurrir fallos fácilmente detectables de forma manual. Del mismo modo se observan multitud de restricciones y esto es debido a lo mencionado anteriormente, errores detectados de forma manual han sido añadidos a las distintas fases de las comprobaciones para que no los considere en posteriores ejecuciones y así poder refinar el emparejamiento de los dataset.




